{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuel/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation \n",
    "\n",
    "As we were given only a small number of images, data augmentation is a must if we plan to use a DNN. By applying small scale rotations, shifts, zooms (rescales), flips and shears, the hope is to significantly increase the number of training samples, while maintaining realism in the images, so as to not degrade the generalization performance (after all, the test set is composed of *real* images)\n",
    "\n",
    "We use the handy keras.preprocessing.image.ImageDataGenerator to facilitate the data augmentation process\n",
    "([keras documentation](https://keras.io/preprocessing/image/))\n",
    "\n",
    "Each image is transformed together with its corresponding mask (so as to keep each pixel correctly labeled).\n",
    "\n",
    "Care has been taken when selecting valid transformations:\n",
    "- Since we are using satellite images, vertical and horizontal flips still remain fairly realistic.\n",
    "- Different training images were also taken at different altitudes (can be seen from the average size of vehicles), so zoom in is also possible.\n",
    "- Zoom out should be limited as the sides are padded, which might degrade segmentation performance on the image's borders.\n",
    "- Rotations are very useful since our training set has a distinct lack of diagonal roads. Since the borders are padded in an unrealistic way, we limit them at 45 degrees [-45, 45].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict(rotation_range=45,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='reflect',\n",
    "                    vertical_flip=True)\n",
    "\n",
    "myGenerator = trainGenerator(20,'data/roadsegmentation/train','image','label',data_gen_args,save_to_dir = \"data/roadsegmentation/train/aug\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 1 classes.\n",
      "Found 100 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# check data/roadsegmentation/train/aug\n",
    "num_batch = 3\n",
    "for i,batch in enumerate(myGenerator):\n",
    "    if(i >= num_batch):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
